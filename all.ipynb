{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import os\n",
    "\n",
    "from math import log10, sqrt\n",
    "\n",
    "DATA_PATH = './CroppedYalePNG'\n",
    "\n",
    "class DataLoader():\n",
    "\tdef __init__(self):\n",
    "\t\tself.data_path = DATA_PATH\n",
    "\t\tself.objs = [i for i in range(1, 40)]\n",
    "\t\tself.objs.remove(14) # data for object 11-18 is not complete, and no 14\n",
    "\t\tself.lights = set()\n",
    "\n",
    "\t\tfor root, dirs, files in os.walk(DATA_PATH, topdown=False):\n",
    "\t\t\tfor name in files:\n",
    "\t\t\t\tfilename = os.path.join(DATA_PATH, name)\n",
    "\t\t\t\tif 'Ambient' in filename:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telse:\n",
    "\n",
    "\t\t\t\t\tparse = filename.split('_')[1][3:].split('.')[0]\n",
    "\t\t\t\t\tself.lights = self.lights.union([parse])\n",
    "\t\tself.lights = list(self.lights)\n",
    "\n",
    "\tdef load_img(self, obj, light):\n",
    "\t\tobj = str(obj)\n",
    "\t\tobj = (2 - len(obj)) * '0' + obj\n",
    "\t\tfilename = 'yaleB' + obj + '_P00' + light + '.png'\n",
    "\t\tfilename = os.path.join(self.data_path, filename)\n",
    "\t\ttry:\n",
    "\t\t\timg = imread(filename)\n",
    "\t\t\treturn img / 255\n",
    "\t\texcept FileNotFoundError:\n",
    "\t\t\treturn None\n",
    "\n",
    "\tdef load_all(self, skip=None):\n",
    "\t\timgs = []\n",
    "\t\tfor o in self.objs:\n",
    "\t\t\tfor l in self.lights:\n",
    "\t\t\t\tif skip is not None and (o,l) in skip:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\timg = self.load_img(o, l)\n",
    "\t\t\t\tif img is not None: imgs.append(img)\n",
    "\t\treturn np.stack(imgs)\n",
    "\n",
    "\tdef load_lights(self, obj):\n",
    "\t\timgs = []\n",
    "\t\tfor l in self.lights:\n",
    "\t\t\timg = self.load_img(obj, l)\n",
    "\t\t\tif img is not None: imgs.append(img)\n",
    "\t\treturn np.stack(imgs)\n",
    "\n",
    "\tdef load_obj(self, light):\n",
    "\t\timgs = []\n",
    "\t\tfor obj in self.objs:\n",
    "\t\t\timg = self.load_img(obj, light)\n",
    "\t\t\tif img is not None: imgs.append(img)\n",
    "\t\treturn np.stack(imgs)\n",
    "\n",
    "def add_noise(img, std):\n",
    "\tstd = std / 255.\n",
    "\tnoise = np.random.normal(scale=std, size=img.shape)\n",
    "\timg = np.clip(img + noise, 0, 1).astype(np.float32)\n",
    "\treturn img\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "\tmse = np.mean((original - compressed) ** 2)\n",
    "\tif(mse == 0):\n",
    "\t\treturn 100\n",
    "\tmax_pixel = 1\n",
    "\tpsnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "\treturn psnr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Markov Random Field\n",
    "\n",
    "here implemented Markov Random Field and Gibbs sampling, where we sample $$Y_{ij} \\sim P(Y_{ij}|others)$$. In markov random field, given the markov blanket of $Y_{ij}$, which is $Y_{i-1,j}, Y_{i+1,j}, Y_{i,j-1}, Y_{i,j+1}, X_{ij}$, we can easily compute the conditional probability.\n",
    "\n",
    "In MRF, we use the energy function\n",
    "$$E(X,Y) = \\alpha \\sum_i \\sum_j ||X_{ij} - Y_{ij}||_1 + \\beta \\sum_{i}\\sum_{j} \\sum_{n \\in N(ij)} ||Y_{ij} - Y_n||_1$$\n",
    "where $N_{ij}$ is the neighbors of $Y_{ij}$, then the probability becomes\n",
    "$$P(X,Y) = \\frac{1}{Z} exp(-E(X,Y))$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data_util import DataLoader, add_noise\n",
    "\n",
    "class MRFGibbs():\n",
    "\tdef __init__(self, alpha, beta):\n",
    "\t\tself.alpha = alpha\n",
    "\t\tself.beta = beta\n",
    "\n",
    "\tdef compute_conditional(self, X, Y, i, j):\n",
    "\t\tm,n = X.shape\n",
    "\t\tys = np.arange(0, 256) / 255\n",
    "\t\tes = self.beta * np.abs(ys - X[i,j]) ** 1\n",
    "\n",
    "\t\tif i-1 >= 0: es += self.alpha * np.abs(ys - Y[i-1,j]) ** 1\n",
    "\t\tif i+1 <  m: es += self.alpha * np.abs(ys - Y[i+1,j]) ** 1\n",
    "\t\tif j-1 >= 0: es += self.alpha * np.abs(ys - Y[i,j-1]) ** 1\n",
    "\t\tif j+1 <  n: es += self.alpha * np.abs(ys - Y[i,j+1]) ** 1\n",
    "\n",
    "\t\tps = np.exp(-es)\n",
    "\t\tps = ps / np.sum(ps)\n",
    "\t\treturn ps\n",
    "\n",
    "\tdef gibbs_sampling_one_iter(self, X, Y):\n",
    "\t\tm,n = X.shape\n",
    "\t\tIs = np.arange(0,m); np.random.shuffle(Is)\n",
    "\t\tJs = np.arange(0,n); np.random.shuffle(Js)\n",
    "\t\tY_copy = Y.copy()\n",
    "\n",
    "\t\tfor i in Is:\n",
    "\t\t\tfor j in Js:\n",
    "\t\t\t\tps = self.compute_conditional(X, Y_copy, i, j)\n",
    "\t\t\t\tidx = np.random.choice(np.arange(len(ps)), p=ps)\n",
    "\t\t\t\t# idx = np.argmax(ps)\n",
    "\t\t\t\tY_copy[i,j] = idx / 255\n",
    "\t\treturn Y_copy\n",
    "\n",
    "\tdef fit(self, X, num_burn=100, num_sampling=1000):\n",
    "\t\tY_copy = X.copy()\n",
    "\t\tfor _ in range(num_burn):\n",
    "\t\t\tY_copy = self.gibbs_sampling_one_iter(X, Y_copy)\n",
    "\t\t\t# fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\t\t\t# ax1.imshow(Y, cmap='gray')\n",
    "\t\t\t# ax2.imshow(Y_copy, cmap='gray')\n",
    "\t\t\t# plt.show()\n",
    "\n",
    "\t\tfor _ in range(num_sampling):\n",
    "\t\t\tY_copy = self.gibbs_sampling_one_iter(X, Y_copy)\n",
    "\t\t\t# fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\t\t\t# ax1.imshow(Y, cmap='gray')\n",
    "\t\t\t# ax2.imshow(Y_copy, cmap='gray')\n",
    "\t\t\t# plt.show()\n",
    "\n",
    "\t\treturn Y_copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = DataLoader()\n",
    "img = d.load_img(1, 'A-025E+00')\n",
    "img_noise = add_noise(img)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.imshow(img_noise, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "mrf = MRFGibbs(1, 1)\n",
    "mrf.fit(img_noise, img_noise)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result of MRF under different scale of noise is shown here\n",
    "\n",
    "![image info](./mrf.png)\n",
    "\n",
    "Here we use $\\alpha=20$ and $\\beta=20$. It's not equals to $\\alpha=2$ and $\\beta=2$. Since for $\\alpha=2$ and $\\beta=2$, the probability would be in the \"flat\" region of exponential function, and the sampling will be very close to uniform sampling and the result is very bad."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Total Variation Minimization\n",
    "\n",
    "In Total Variation Minimzation, we solve a very simple optimization problem\n",
    "\n",
    "$$\n",
    "\tmin_{\\hat{X},E} \\quad TotalVariation(\\hat{X}) + \\lambda\\|E\\|_1\\\\\n",
    "\ts.t.\\quad X = \\hat{X} + E\n",
    "$$\n",
    "where the total variation is\n",
    "$$\n",
    "\tTotalVariation(X) = \\|X[:,1:] - X[:,:-1]\\|_1 + \\|X[1:,:] - X[:-1,:]\\|_1\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cvxpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_util import DataLoader, add_noise\n",
    "\n",
    "class TVDenoise():\n",
    "\tdef __init__(self, lamb):\n",
    "\t\tself.lamb = lamb\n",
    "\n",
    "\tdef fit(self, img):\n",
    "\t\tm,n = img.shape\n",
    "\t\tX = cvxpy.Variable([m, n])\n",
    "\t\tE = cvxpy.Variable(shape=[m, n])\n",
    "\t\tp = cvxpy.Problem(\n",
    "\t\t\tcvxpy.Minimize(\n",
    "\t\t\t\tcvxpy.sum(cvxpy.abs(X[1:, :] - X[:-1, :])) + cvxpy.sum(\n",
    "\t\t\t\t\tcvxpy.abs(X[:, 1:] - X[:, :-1])) + 2. * cvxpy.sum(cvxpy.abs(E))\n",
    "\t\t\t),\n",
    "\t\t\t[img == X + E]\n",
    "\t\t)\n",
    "\t\tp.solve()\n",
    "\t\treturn X.value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result of MRF under different scale of noise is shown here\n",
    "\n",
    "[<img src=\"./TV.png\" width=\"500\"/>](image.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Low Rank Representation\n",
    "Here, we flatten all images and stack them along the column axis. Since there are many images and only a few people, we assume the matrix X can be decomposed as a low rank matrix plus some error term\n",
    "\n",
    "\n",
    "[<img src=\"./lr.png\" width=\"800\"/>](image.png)\n",
    "Therefore, we can formulate our optimization problem as following:\n",
    "\n",
    "$$\n",
    "\tmin_{Z,E}\\quad Rank(Z) + \\lambda \\|E\\|_{2,1}\\\\\n",
    "\ts.t. \\quad X=XZ+E\n",
    "$$\n",
    "where $X$ represents data, $XZ$ is the low rank representation and $E$ is the error term.\n",
    "Since minimizing matrix rank is NP hard, we can approximate it by nuclear norm minimization. Then the optimization problem becomes\n",
    "$$\n",
    "\tmin_{Z,E}\\quad \\|Z\\|_{*}+\\lambda \\|E\\|_{2,1}\\\\\n",
    "\ts.t.\\quad \\quad X=XZ+E\n",
    "$$\n",
    "and we can solve it with Augmented Lagrangian Multiplier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as SP\n",
    "\n",
    "def solve_l2(w:np.array, alpha):\n",
    "\t\"\"\"\n",
    "\tSolve the optimization problem:\n",
    "\t\tmin. alpha * ||x||_2 + 0.5 * ||x-w||_2^2\n",
    "\t\"\"\"\n",
    "\tnw = np.linalg.norm(w)\n",
    "\tif nw > alpha:\n",
    "\t\treturn (nw - alpha) / nw * w\n",
    "\telse:\n",
    "\t\treturn np.zeros_like(w)\n",
    "\n",
    "def solve_l21(W:np.array, alpha):\n",
    "\t\"\"\"\n",
    "\tSolve the optimization problem\n",
    "\t\tmin. alpha * ||E||_{2,1} + ||E - W||_2^2\n",
    "\t\"\"\"\n",
    "\tE = np.zeros_like(W)\n",
    "\tm, n = W.shape\n",
    "\tfor i in range(n):\n",
    "\t\tE[:,i] = solve_l2(W[:,i], alpha)\n",
    "\treturn E\n",
    "\n",
    "def singular_value_shrink(A, alpha):\n",
    "\tU, lamb, VT = np.linalg.svd(A)\n",
    "\tidx = np.where(lamb > alpha)[0]\n",
    "\t# print(idx)\n",
    "\tif len(idx) == 0:\n",
    "\t\treturn np.zeros_like(A)\n",
    "\telif len(idx) == 1:\n",
    "\t\treturn np.outer(U[:,0], (lamb[0] - alpha) * VT[0,:])\n",
    "\telse:\n",
    "\t\tdiags = np.maximum(lamb[idx] - alpha,0)\n",
    "\t\treturn U[:,idx] @ SP.diags(diags).dot(VT[idx,:])\n",
    "\n",
    "def __solve_low_rank_representation(X:np.array, A:np.array, lamb):\n",
    "\t\"\"\"\n",
    "\tSolve the nuclear-norm optimization problem\n",
    "\t\tmin. ||Z||_* + lamb * ||E||_{2,1}\n",
    "\t\ts.t. X = AZ + E\n",
    "\tby solving the equivalent problem\n",
    "\t\tmin. ||J||_* + lamb * ||E||_{2,1}\n",
    "\t\ts.t. X = AZ + E\n",
    "\t\t\t Z = J\n",
    "\tusing Augmented Lagrangian Multiplier\n",
    "\n",
    "\t:param X: Of shape [d, n], d is data dimensions, n is number of data\n",
    "\t:param A: Of shape [d, m], a dictionary\n",
    "\t:param lamb:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tprint(X.shape, A.shape)\n",
    "\n",
    "\ttol = 1e-8\n",
    "\tmaxIter = 1e6\n",
    "\td, n = X.shape\n",
    "\td, m = A.shape\n",
    "\tc = 1e-3\n",
    "\tmaxc = 1e10\n",
    "\trho = 1.2\n",
    "\n",
    "\t# Initialize primal variables\n",
    "\tJ = np.zeros(shape=[m,n])\n",
    "\tZ = np.zeros(shape=[m,n])\n",
    "\t# E = np.zeros(shape=[d,n])\n",
    "\tE = np.random.randn(d,n)\n",
    "\n",
    "\t# Initialize dual variables\n",
    "\tY1 = np.zeros(shape=[d,n])\n",
    "\tY2 = np.zeros(shape=[m,n])\n",
    "\n",
    "\t# Some data that will be used many times\n",
    "\tinv_atapi = np.linalg.inv(A.T @ A + np.eye(m))\n",
    "\tatx = A.T @ X\n",
    "\n",
    "\titer = 0\n",
    "\tconvergence = False\n",
    "\tranks = []\n",
    "\twhile not convergence:\n",
    "\t\titer += 1\n",
    "\n",
    "\t\t# Update primal variabble J\n",
    "\t\tJ = singular_value_shrink(Z + Y2 / c, 1/c)\n",
    "\n",
    "\t\t# Update primal variable Z\n",
    "\t\tZ = inv_atapi @ (atx - A.T@E + J + (A.T @ Y1 - Y2)/c)\n",
    "\n",
    "\n",
    "\t\t# Update primal variable E\n",
    "\t\txmaz = X - A @ Z\n",
    "\t\tE = solve_l21(xmaz + Y1 / c, alpha=lamb/c)\n",
    "\t\t# E = solve_l1_plus_fro(xmaz + Y1 / c, c / (2 * lamb))\n",
    "\t\t# Update dual variable Y1 and Y2\n",
    "\t\tleq1 = xmaz - E # linear equality 1\n",
    "\t\tleq2 = Z - J    # linear equality 2\n",
    "\t\tY1 += c * leq1\n",
    "\t\tY2 += c * leq2\n",
    "\n",
    "\t\tranks.append(np.linalg.matrix_rank(Z,tol=1e-3*np.linalg.norm(Z, 2)))\n",
    "\t\t# if iter % 10 == 0:\n",
    "\t\tprint(\"Iteration %d, c:%.6f, Rank:%d, Equality 1 violation: %.5f, Equality 2 violation: %.5f\"\n",
    "\t\t\t  %\n",
    "\t\t\t  (iter, c, np.linalg.matrix_rank(Z,tol=1e-3*np.linalg.norm(Z, 2)), np.max(np.abs(leq1)), np.max(np.abs(leq2)))\n",
    "\t\t)\n",
    "\t\tc = min(c * rho, maxc)\n",
    "\n",
    "\n",
    "\t\tif max(np.max(np.abs(leq1)), np.max(np.abs(leq2))) < tol:\n",
    "\t\t\tconvergence = True\n",
    "\n",
    "\treturn Z, E, ranks\n",
    "\n",
    "def solve_low_rank_representation(X, lamb):\n",
    "\t\"\"\"\n",
    "\n",
    "\t:param X: Of shape [d, n], d is data dimensions, n is number of data\n",
    "\t:param lamb:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\t# Q = orth(X.T)\n",
    "\t# A = X @ Q\n",
    "\tZ, E, ranks = __solve_low_rank_representation(X, X, lamb)\n",
    "\n",
    "\n",
    "\treturn X @ Z, E, ranks\n",
    "\n",
    "class LowRankDenoise():\n",
    "\tdef __init__(self, lamb, data):\n",
    "\t\tself.lamb = lamb\n",
    "\t\tself.data = np.reshape(data, [data.shape[0], -1])\n",
    "\n",
    "\tdef fit(self, imgs):\n",
    "\t\t\"\"\"\n",
    "\t\t:param img: of shape [m,h,w]\n",
    "\t\t\"\"\"\n",
    "\t\tm, h, w = imgs.shape\n",
    "\t\timgs = np.reshape(imgs, [m, h * w])\n",
    "\t\tdata = np.concatenate([imgs, self.data]).T\n",
    "\t\trecover, E, ranks = solve_low_rank_representation(data, self.lamb)\n",
    "\t\trecover = recover.T[:m]\n",
    "\t\trecover = np.reshape(recover, [m,h,w])\n",
    "\t\treturn recover, ranks\n",
    "\n",
    "objs = [\n",
    "\t\t(1, 'A-020E+10'),\n",
    "\t\t(2, 'A-010E+00'),\n",
    "\t\t(3, 'A-020E-10'),\n",
    "\t\t(6, 'A+020E+10'),\n",
    "\t\t(7, 'A+000E+00')\n",
    "\t]\n",
    "std = 25\n",
    "lamb = 0.005\n",
    "\n",
    "d = DataLoader()\n",
    "data = d.load_all(skip=objs)[:1000]\n",
    "\n",
    "model = LowRankDenoise(lamb, data)\n",
    "\n",
    "imgs_origin = []\n",
    "imgs_noisy = []\n",
    "for idx, light in objs:\n",
    "    img = d.load_img(idx, light)\n",
    "    img_noise = add_noise(img, std)\n",
    "\n",
    "    imgs_origin.append(img)\n",
    "    imgs_noisy.append(img_noise)\n",
    "\n",
    "imgs_noisy = np.array(imgs_noisy)\n",
    "\n",
    "imgs_denoise, ranks, others = model.fit(imgs_noisy)\n",
    "\n",
    "for i, (idx, light) in enumerate(objs):\n",
    "    result = PSNR(imgs_origin[i], imgs_noisy[i])\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    ax1.imshow(imgs_origin[i], cmap='gray')\n",
    "    ax1.set_title('Original')\n",
    "    ax2.imshow(imgs_noisy[i], cmap='gray')\n",
    "    ax2.set_title(r'Noised with Gaussian $\\sigma^2=%d$' % (std))\n",
    "    ax3.imshow(imgs_denoise[i], cmap='gray')\n",
    "    ax3.set_title('After Denoising by Low Rank Representation \\n PSNR %.2f dB' % (result))\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    plt.savefig('./%d_%s_%d.png' % (idx, light, std))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The rank of $XZ$ decreases over iterations as shown in the following figure.\n",
    "[<img src=\"./ranks.jpg\" width=\"400\"/>](image.png)\n",
    "\n",
    "The result of low rank representaion is shown in the figure below.\n",
    "\n",
    "[<img src=\"./lowrank.png\" width=\"400\"/>](image.png)\n",
    "\n",
    "The PSNR score is not very high.  However, low rank representation has some interesting side effect. he left part is the original image, and the right part is the low-rank representation. We can see that this method recover some corruption in the image. In the first image, the shade near the nose is eliminated, and in the second image, it kind of recovered the left eye. Maybe we can use Low-rank representation for image restoration.\n",
    "\n",
    "[<img src=\"./lowrank_se.png\" width=\"400\"/>](image.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNet\n",
    "\n",
    "Lehtinen, Jaakko, et al. \"Noise2Noise: Learning image restoration without clean data.\" arXiv preprint arXiv:1803.04189 (2018).\n",
    "We also tried deep learning method. We used a U-net, where we add noise to corrupted image as input and the corrupted images without additional noise as label. We use 2k images as training set, and 200 images for validation set. For the input, we randomly add noise to the (corrupted) original image. Here is the result of the U-net model. The PSNR values are higher than all previous models in for all kinds of noises, and the visual effect is also very good."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"Custom U-Net architecture for Noise2Noise (see Appendix, Table 2).\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        \"\"\"Initializes U-Net.\"\"\"\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Layers: enc_conv0, enc_conv1, pool1\n",
    "        self._block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(48, 48, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # Layers: enc_conv(i), pool(i); i=2..5\n",
    "        self._block2 = nn.Sequential(\n",
    "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # Layers: enc_conv6, upsample5\n",
    "        self._block3 = nn.Sequential(\n",
    "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_conv5a, dec_conv5b, upsample4\n",
    "        self._block4 = nn.Sequential(\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_deconv(i)a, dec_deconv(i)b, upsample(i-1); i=4..2\n",
    "        self._block5 = nn.Sequential(\n",
    "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_conv1a, dec_conv1b, dec_conv1c,\n",
    "        self._block6 = nn.Sequential(\n",
    "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1))\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initializes weights using He et al. (2015).\"\"\"\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Through encoder, then decoder by adding U-skip connections. \"\"\"\n",
    "        # Encoder\n",
    "        pool1 = self._block1(x)\n",
    "        pool2 = self._block2(pool1)\n",
    "        pool3 = self._block2(pool2)\n",
    "        pool4 = self._block2(pool3)\n",
    "        pool5 = self._block2(pool4)\n",
    "\n",
    "        # Decoder\n",
    "        upsample5 = self._block3(pool5)\n",
    "        concat5 = torch.cat((upsample5, pool4), dim=1)\n",
    "        upsample4 = self._block4(concat5)\n",
    "        concat4 = torch.cat((upsample4, pool3), dim=1)\n",
    "        upsample3 = self._block5(concat4)\n",
    "        concat3 = torch.cat((upsample3, pool2), dim=1)\n",
    "        upsample2 = self._block5(concat3)\n",
    "        concat2 = torch.cat((upsample2, pool1), dim=1)\n",
    "        upsample1 = self._block5(concat2)\n",
    "        concat1 = torch.cat((upsample1, x), dim=1)\n",
    "\n",
    "        # Final activation\n",
    "        return self._block6(concat1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as tvF\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from math import log10\n",
    "from datetime import datetime\n",
    "import OpenEXR\n",
    "from PIL import Image\n",
    "import Imath\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def clear_line():\n",
    "    \"\"\"Clears line from any characters.\"\"\"\n",
    "\n",
    "    print('\\r{}'.format(' ' * 80), end='\\r')\n",
    "\n",
    "\n",
    "def progress_bar(batch_idx, num_batches, report_interval, train_loss):\n",
    "    \"\"\"Neat progress bar to track training.\"\"\"\n",
    "\n",
    "    dec = int(np.ceil(np.log10(num_batches)))\n",
    "    bar_size = 21 + dec\n",
    "    progress = (batch_idx % report_interval) / report_interval\n",
    "    fill = int(progress * bar_size) + 1\n",
    "    print('\\rBatch {:>{dec}d} [{}{}] Train loss: {:>1.5f}'.format(batch_idx + 1, '=' * fill + '>', ' ' * (bar_size - fill), train_loss, dec=str(dec)), end='')\n",
    "\n",
    "\n",
    "def time_elapsed_since(start):\n",
    "    \"\"\"Computes elapsed time since start.\"\"\"\n",
    "\n",
    "    timedelta = datetime.now() - start\n",
    "    string = str(timedelta)[:-7]\n",
    "    ms = int(timedelta.total_seconds() * 1000)\n",
    "\n",
    "    return string, ms\n",
    "\n",
    "\n",
    "def show_on_epoch_end(epoch_time, valid_time, valid_loss, valid_psnr):\n",
    "    \"\"\"Formats validation error stats.\"\"\"\n",
    "\n",
    "    clear_line()\n",
    "    print('Train time: {} | Valid time: {} | Valid loss: {:>1.5f} | Avg PSNR: {:.2f} dB'.format(epoch_time, valid_time, valid_loss, valid_psnr))\n",
    "\n",
    "\n",
    "def show_on_report(batch_idx, num_batches, loss, elapsed):\n",
    "    \"\"\"Formats training stats.\"\"\"\n",
    "\n",
    "    clear_line()\n",
    "    dec = int(np.ceil(np.log10(num_batches)))\n",
    "    print('Batch {:>{dec}d} / {:d} | Avg loss: {:>1.5f} | Avg train time / batch: {:d} ms'.format(batch_idx + 1, num_batches, loss, int(elapsed), dec=dec))\n",
    "\n",
    "\n",
    "def plot_per_epoch(ckpt_dir, title, measurements, y_label):\n",
    "    \"\"\"Plots stats (train/valid loss, avg PSNR, etc.).\"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(range(1, len(measurements) + 1), measurements)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = '{}.png'.format(title.replace(' ', '-').lower())\n",
    "    plot_fname = os.path.join(ckpt_dir, fname)\n",
    "    plt.savefig(plot_fname, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def load_hdr_as_tensor(img_path):\n",
    "    \"\"\"Converts OpenEXR image to torch float tensor.\"\"\"\n",
    "\n",
    "    # Read OpenEXR file\n",
    "    if not OpenEXR.isOpenExrFile(img_path):\n",
    "        raise ValueError(f'Image {img_path} is not a valid OpenEXR file')\n",
    "    src = OpenEXR.InputFile(img_path)\n",
    "    pixel_type = Imath.PixelType(Imath.PixelType.FLOAT)\n",
    "    dw = src.header()['dataWindow']\n",
    "    size = (dw.max.x - dw.min.x + 1, dw.max.y - dw.min.y + 1)\n",
    "\n",
    "    # Read into tensor\n",
    "    tensor = torch.zeros((3, size[1], size[0]))\n",
    "    for i, c in enumerate('RGB'):\n",
    "        rgb32f = np.fromstring(src.channel(c, pixel_type), dtype=np.float32)\n",
    "        tensor[i, :, :] = torch.from_numpy(rgb32f.reshape(size[1], size[0]))\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def reinhard_tonemap(tensor):\n",
    "    \"\"\"Reinhard et al. (2002) tone mapping.\"\"\"\n",
    "\n",
    "    tensor[tensor < 0] = 0\n",
    "    return torch.pow(tensor / (1 + tensor), 1 / 2.2)\n",
    "\n",
    "\n",
    "def psnr(input, target):\n",
    "    \"\"\"Computes peak signal-to-noise ratio.\"\"\"\n",
    "\n",
    "    return 10 * torch.log10(1 / F.mse_loss(input, target))\n",
    "\n",
    "\n",
    "def create_montage(img_name, noise_type, save_path, source_t, denoised_t, clean_t, show):\n",
    "    \"\"\"Creates montage for easy comparison.\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(30, 10))\n",
    "    fig.canvas.set_window_title(img_name.capitalize()[:-4])\n",
    "\n",
    "    # Bring tensors to CPU\n",
    "    source_t = source_t.cpu().narrow(0, 0, 3)\n",
    "    denoised_t = denoised_t.cpu()\n",
    "    clean_t = clean_t.cpu()\n",
    "\n",
    "    source = tvF.to_pil_image(source_t)\n",
    "    denoised = tvF.to_pil_image(torch.clamp(denoised_t, 0, 1))\n",
    "    clean = tvF.to_pil_image(clean_t)\n",
    "\n",
    "    # Build image montage\n",
    "    psnr_vals = [psnr(source_t, clean_t), psnr(denoised_t, clean_t)]\n",
    "    titles = ['Original',\n",
    "              'Gaussian noise with sigma^2=9',\n",
    "              'Denoised by Noise2Noise\\n PNSR {:.2f} dB'.format(psnr_vals[1])]\n",
    "    zipped = zip(titles, [clean, source, denoised])\n",
    "    for j, (title, img) in enumerate(zipped):\n",
    "        ax[j].imshow(img)\n",
    "        ax[j].set_title(title, fontsize=30)\n",
    "        # ax[j].axis('off')\n",
    "\n",
    "    # Open pop up window, if requested\n",
    "    if show > 0:\n",
    "        plt.show()\n",
    "\n",
    "    # Save to files\n",
    "    fname = os.path.splitext(img_name)[0]\n",
    "    source.save(os.path.join(save_path, f'{fname}-{noise_type}-noisy.png'))\n",
    "    denoised.save(os.path.join(save_path, f'{fname}-{noise_type}-denoised.png'))\n",
    "    fig.savefig(os.path.join(save_path, f'{fname}-{noise_type}-montage.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "class AvgMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\n",
    "    Useful for tracking averages such as elapsed times, minibatch losses, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0.\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "class Noise2Noise(object):\n",
    "    \"\"\"Implementation of Noise2Noise from Lehtinen et al. (2018).\"\"\"\n",
    "\n",
    "    def __init__(self, params, trainable):\n",
    "        \"\"\"Initializes model.\"\"\"\n",
    "\n",
    "        self.p = params\n",
    "        self.trainable = trainable\n",
    "        self._compile()\n",
    "\n",
    "\n",
    "    def _compile(self):\n",
    "        \"\"\"Compiles model (architecture, loss function, optimizers, etc.).\"\"\"\n",
    "\n",
    "        print('Noise2Noise: Learning Image Restoration without Clean Data (Lethinen et al., 2018)')\n",
    "\n",
    "        # Model (3x3=9 channels for Monte Carlo since it uses 3 HDR buffers)\n",
    "        if self.p.noise_type == 'mc':\n",
    "            self.is_mc = True\n",
    "            self.model = UNet(in_channels=9)\n",
    "        else:\n",
    "            self.is_mc = False\n",
    "            self.model = UNet(in_channels=3)\n",
    "\n",
    "        # Set optimizer and loss, if in training mode\n",
    "        if self.trainable:\n",
    "            self.optim = Adam(self.model.parameters(),\n",
    "                              lr=self.p.learning_rate,\n",
    "                              betas=self.p.adam[:2],\n",
    "                              eps=self.p.adam[2])\n",
    "\n",
    "            # Learning rate adjustment\n",
    "            self.scheduler = lr_scheduler.ReduceLROnPlateau(self.optim,\n",
    "                patience=self.p.nb_epochs/4, factor=0.5, verbose=True)\n",
    "\n",
    "            # Loss function\n",
    "            if self.p.loss == 'hdr':\n",
    "                assert self.is_mc, 'Using HDR loss on non Monte Carlo images'\n",
    "                self.loss = HDRLoss()\n",
    "            elif self.p.loss == 'l2':\n",
    "                self.loss = nn.MSELoss()\n",
    "            else:\n",
    "                self.loss = nn.L1Loss()\n",
    "\n",
    "        # CUDA support\n",
    "        self.use_cuda = torch.cuda.is_available() and self.p.cuda\n",
    "        if self.use_cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            if self.trainable:\n",
    "                self.loss = self.loss.cuda()\n",
    "\n",
    "\n",
    "    def _print_params(self):\n",
    "        \"\"\"Formats parameters to print when training.\"\"\"\n",
    "\n",
    "        print('Training parameters: ')\n",
    "        self.p.cuda = self.use_cuda\n",
    "        param_dict = vars(self.p)\n",
    "        pretty = lambda x: x.replace('_', ' ').capitalize()\n",
    "        print('\\n'.join('  {} = {}'.format(pretty(k), str(v)) for k, v in param_dict.items()))\n",
    "        print()\n",
    "\n",
    "\n",
    "    def save_model(self, epoch, stats, first=False):\n",
    "        \"\"\"Saves model to files; can be overwritten at every epoch to save disk space.\"\"\"\n",
    "\n",
    "        # Create directory for model checkpoints, if nonexistent\n",
    "        if first:\n",
    "            if self.p.clean_targets:\n",
    "                ckpt_dir_name = f'{datetime.now():{self.p.noise_type}-clean-%H%M}'\n",
    "            else:\n",
    "                ckpt_dir_name = f'{datetime.now():{self.p.noise_type}-%H%M}'\n",
    "            if self.p.ckpt_overwrite:\n",
    "                if self.p.clean_targets:\n",
    "                    ckpt_dir_name = f'{self.p.noise_type}-clean'\n",
    "                else:\n",
    "                    ckpt_dir_name = self.p.noise_type\n",
    "\n",
    "            self.ckpt_dir = os.path.join(self.p.ckpt_save_path, ckpt_dir_name)\n",
    "            if not os.path.isdir(self.p.ckpt_save_path):\n",
    "                os.mkdir(self.p.ckpt_save_path)\n",
    "            if not os.path.isdir(self.ckpt_dir):\n",
    "                os.mkdir(self.ckpt_dir)\n",
    "\n",
    "        # Save checkpoint dictionary\n",
    "        if self.p.ckpt_overwrite:\n",
    "            fname_unet = '{}/n2n-{}.pt'.format(self.ckpt_dir, self.p.noise_type)\n",
    "        else:\n",
    "            valid_loss = stats['valid_loss'][epoch]\n",
    "            fname_unet = '{}/n2n-epoch{}-{:>1.5f}.pt'.format(self.ckpt_dir, epoch + 1, valid_loss)\n",
    "        print('Saving checkpoint to: {}\\n'.format(fname_unet))\n",
    "        torch.save(self.model.state_dict(), fname_unet)\n",
    "\n",
    "        # Save stats to JSON\n",
    "        fname_dict = '{}/n2n-stats.json'.format(self.ckpt_dir)\n",
    "        with open(fname_dict, 'w') as fp:\n",
    "            json.dump(stats, fp, indent=2)\n",
    "\n",
    "\n",
    "    def load_model(self, ckpt_fname):\n",
    "        \"\"\"Loads model from checkpoint file.\"\"\"\n",
    "\n",
    "        print('Loading checkpoint from: {}'.format(ckpt_fname))\n",
    "        if self.use_cuda:\n",
    "            self.model.load_state_dict(torch.load(ckpt_fname))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(ckpt_fname, map_location='cpu'))\n",
    "\n",
    "\n",
    "    def _on_epoch_end(self, stats, train_loss, epoch, epoch_start, valid_loader):\n",
    "        \"\"\"Tracks and saves starts after each epoch.\"\"\"\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        print('\\rTesting model on validation set... ', end='')\n",
    "        epoch_time = time_elapsed_since(epoch_start)[0]\n",
    "        valid_loss, valid_time, valid_psnr = self.eval(valid_loader)\n",
    "        show_on_epoch_end(epoch_time, valid_time, valid_loss, valid_psnr)\n",
    "\n",
    "        # Decrease learning rate if plateau\n",
    "        self.scheduler.step(valid_loss)\n",
    "\n",
    "        # Save checkpoint\n",
    "        stats['train_loss'].append(train_loss)\n",
    "        stats['valid_loss'].append(valid_loss)\n",
    "        stats['valid_psnr'].append(valid_psnr)\n",
    "        self.save_model(epoch, stats, epoch == 0)\n",
    "\n",
    "        # Plot stats\n",
    "        if self.p.plot_stats:\n",
    "            loss_str = f'{self.p.loss.upper()} loss'\n",
    "            plot_per_epoch(self.ckpt_dir, 'Valid loss', stats['valid_loss'], loss_str)\n",
    "            plot_per_epoch(self.ckpt_dir, 'Valid PSNR', stats['valid_psnr'], 'PSNR (dB)')\n",
    "\n",
    "\n",
    "    def test(self, test_loader, show, denoised_dir):\n",
    "        \"\"\"Evaluates denoiser on test set.\"\"\"\n",
    "\n",
    "        self.model.train(False)\n",
    "\n",
    "        source_imgs = []\n",
    "        denoised_imgs = []\n",
    "        clean_imgs = []\n",
    "\n",
    "        # Create directory for denoised images\n",
    "        # denoised_dir = os.path.dirname(denoised_dir)\n",
    "        # save_path = os.path.join(denoised_dir, 'denoised')\n",
    "        save_path = denoised_dir\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for batch_idx, (source, target) in enumerate(test_loader):\n",
    "            # Only do first <show> images\n",
    "            if show == 0 or batch_idx >= show:\n",
    "                break\n",
    "\n",
    "            source_imgs.append(source)\n",
    "            clean_imgs.append(target)\n",
    "\n",
    "            if self.use_cuda:\n",
    "                source = source.cuda()\n",
    "\n",
    "            # Denoise\n",
    "            denoised_img = self.model(source).detach()\n",
    "            denoised_imgs.append(denoised_img)\n",
    "\n",
    "        # Squeeze tensors\n",
    "        source_imgs = [t.squeeze(0) for t in source_imgs]\n",
    "        denoised_imgs = [t.squeeze(0) for t in denoised_imgs]\n",
    "        clean_imgs = [t.squeeze(0) for t in clean_imgs]\n",
    "\n",
    "        # Create montage and save images\n",
    "        print('Saving images and montages to: {}'.format(save_path))\n",
    "        for i in range(len(source_imgs)):\n",
    "            img_name = test_loader.dataset.imgs[i]\n",
    "            create_montage(img_name, self.p.noise_type, save_path, source_imgs[i], denoised_imgs[i], clean_imgs[i], show)\n",
    "\n",
    "\n",
    "    def eval(self, valid_loader):\n",
    "        \"\"\"Evaluates denoiser on validation set.\"\"\"\n",
    "\n",
    "        self.model.train(False)\n",
    "\n",
    "        valid_start = datetime.now()\n",
    "        loss_meter = AvgMeter()\n",
    "        psnr_meter = AvgMeter()\n",
    "\n",
    "        for batch_idx, (source, target) in enumerate(valid_loader):\n",
    "            if self.use_cuda:\n",
    "                source = source.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # Denoise\n",
    "            source_denoised = self.model(source)\n",
    "\n",
    "            # Update loss\n",
    "            loss = self.loss(source_denoised, target)\n",
    "            loss_meter.update(loss.item())\n",
    "\n",
    "            # Compute PSRN\n",
    "            if self.is_mc:\n",
    "                source_denoised = reinhard_tonemap(source_denoised)\n",
    "            # TODO: Find a way to offload to GPU, and deal with uneven batch sizes\n",
    "            for i in range(self.p.batch_size):\n",
    "                source_denoised = source_denoised.cpu()\n",
    "                target = target.cpu()\n",
    "                psnr_meter.update(psnr(source_denoised[i], target[i]).item())\n",
    "\n",
    "        valid_loss = loss_meter.avg\n",
    "        valid_time = time_elapsed_since(valid_start)[0]\n",
    "        psnr_avg = psnr_meter.avg\n",
    "\n",
    "        return valid_loss, valid_time, psnr_avg\n",
    "\n",
    "\n",
    "    def train(self, train_loader, valid_loader):\n",
    "        \"\"\"Trains denoiser on training set.\"\"\"\n",
    "\n",
    "        self.model.train(True)\n",
    "\n",
    "        self._print_params()\n",
    "        num_batches = len(train_loader)\n",
    "        assert num_batches % self.p.report_interval == 0, 'Report interval must divide total number of batches'\n",
    "\n",
    "        # Dictionaries of tracked stats\n",
    "        stats = {'noise_type': self.p.noise_type,\n",
    "                 'noise_param': self.p.noise_param,\n",
    "                 'train_loss': [],\n",
    "                 'valid_loss': [],\n",
    "                 'valid_psnr': []}\n",
    "\n",
    "        # Main training loop\n",
    "        train_start = datetime.now()\n",
    "        for epoch in range(self.p.nb_epochs):\n",
    "            print('EPOCH {:d} / {:d}'.format(epoch + 1, self.p.nb_epochs))\n",
    "\n",
    "            # Some stats trackers\n",
    "            epoch_start = datetime.now()\n",
    "            train_loss_meter = AvgMeter()\n",
    "            loss_meter = AvgMeter()\n",
    "            time_meter = AvgMeter()\n",
    "\n",
    "            # Minibatch SGD\n",
    "            for batch_idx, (source, target) in enumerate(train_loader):\n",
    "                batch_start = datetime.now()\n",
    "                progress_bar(batch_idx, num_batches, self.p.report_interval, loss_meter.val)\n",
    "\n",
    "                if self.use_cuda:\n",
    "                    source = source.cuda()\n",
    "                    target = target.cuda()\n",
    "\n",
    "                # Denoise image\n",
    "                source_denoised = self.model(source)\n",
    "\n",
    "                loss = self.loss(source_denoised, target)\n",
    "                loss_meter.update(loss.item())\n",
    "\n",
    "                # Zero gradients, perform a backward pass, and update the weights\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                # Report/update statistics\n",
    "                time_meter.update(time_elapsed_since(batch_start)[1])\n",
    "                if (batch_idx + 1) % self.p.report_interval == 0 and batch_idx:\n",
    "                    show_on_report(batch_idx, num_batches, loss_meter.avg, time_meter.avg)\n",
    "                    train_loss_meter.update(loss_meter.avg)\n",
    "                    loss_meter.reset()\n",
    "                    time_meter.reset()\n",
    "\n",
    "            # Epoch end, save and reset tracker\n",
    "            self._on_epoch_end(stats, train_loss_meter.avg, epoch, epoch_start, valid_loader)\n",
    "            train_loss_meter.reset()\n",
    "\n",
    "        train_elapsed = time_elapsed_since(train_start)[0]\n",
    "        print('Training done! Total elapsed time: {}\\n'.format(train_elapsed))\n",
    "\n",
    "\n",
    "class HDRLoss(nn.Module):\n",
    "    \"\"\"High dynamic range loss.\"\"\"\n",
    "\n",
    "    def __init__(self, eps=0.01):\n",
    "        \"\"\"Initializes loss with numerical stability epsilon.\"\"\"\n",
    "\n",
    "        super(HDRLoss, self).__init__()\n",
    "        self._eps = eps\n",
    "\n",
    "\n",
    "    def forward(self, denoised, target):\n",
    "        \"\"\"Computes loss by unpacking render buffer.\"\"\"\n",
    "\n",
    "        loss = ((denoised - target) ** 2) / (denoised + self._eps) ** 2\n",
    "        return torch.mean(loss.view(-1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the result of UNet model.\n",
    "The PSNR values are higher than all previous models in for all kinds of noises, and the visual effect is also very good.\n",
    "\n",
    "[<img src=\"./n2n.png\" width=\"300\"/>](image.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Image Prior\n",
    "\n",
    ", one drawback of deep learning Is that it need a lot of data to have good performance. Can we get rid of this data-dependency? Our answer is yes. If we look and our previous methods, all of them can be formulated into the following  form.\n",
    "$$\n",
    "    min_{X} E(X,X_0) + R(X)\n",
    "$$\n",
    "\n",
    "We want to make the prediction image close to the noisy image under some regularization. In MRF and Total Variation Minimization, the regularization is that the prediction image has low variation, and in low rank representation, we assume the original images come from a low-rank subspace.  In deep image prior, we want the prediction to be very close to the noisy image, subject to the regularization that the prediction is produced by a deep CNN.  Here we use the architecture of CNN as prior. The motivation is, in Deep CNN, we stack some convolution layers together and wish it to extract some semantic meaning of the image, and they are pretty good at this than other architectures. So, the architecture of the Deep CNN may encodes prior knowledge about how an image should look like.  In Deep Image prior, we input a random noise and output an image, then optimize the weights of the CNN to make the prediction close to the noisy image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crop_image(img, d=32):\n",
    "    '''Make dimensions divisible by `d`'''\n",
    "\n",
    "    new_size = (img.size[0] - img.size[0] % d,\n",
    "                img.size[1] - img.size[1] % d)\n",
    "\n",
    "    bbox = [\n",
    "            int((img.size[0] - new_size[0])/2),\n",
    "            int((img.size[1] - new_size[1])/2),\n",
    "            int((img.size[0] + new_size[0])/2),\n",
    "            int((img.size[1] + new_size[1])/2),\n",
    "    ]\n",
    "\n",
    "    img_cropped = img.crop(bbox)\n",
    "    return img_cropped\n",
    "\n",
    "def get_params(opt_over, net, net_input, downsampler=None):\n",
    "    '''Returns parameters that we want to optimize over.\n",
    "\n",
    "    Args:\n",
    "        opt_over: comma separated list, e.g. \"net,input\" or \"net\"\n",
    "        net: network\n",
    "        net_input: torch.Tensor that stores input `z`\n",
    "    '''\n",
    "    opt_over_list = opt_over.split(',')\n",
    "    params = []\n",
    "\n",
    "    for opt in opt_over_list:\n",
    "\n",
    "        if opt == 'net':\n",
    "            params += [x for x in net.parameters() ]\n",
    "        elif  opt=='down':\n",
    "            assert downsampler is not None\n",
    "            params = [x for x in downsampler.parameters()]\n",
    "        elif opt == 'input':\n",
    "            net_input.requires_grad = True\n",
    "            params += [net_input]\n",
    "        else:\n",
    "            assert False, 'what is it?'\n",
    "\n",
    "    return params\n",
    "\n",
    "def get_image_grid(images_np, nrow=8):\n",
    "    '''Creates a grid from a list of images by concatenating them.'''\n",
    "    images_torch = [torch.from_numpy(x) for x in images_np]\n",
    "    torch_grid = torchvision.utils.make_grid(images_torch, nrow)\n",
    "\n",
    "    return torch_grid.numpy()\n",
    "\n",
    "def plot_image_grid(images_np, nrow =8, factor=1, interpolation='lanczos'):\n",
    "    \"\"\"Draws images in a grid\n",
    "\n",
    "    Args:\n",
    "        images_np: list of images, each image is np.array of size 3xHxW of 1xHxW\n",
    "        nrow: how many images will be in one row\n",
    "        factor: size if the plt.figure\n",
    "        interpolation: interpolation used in plt.imshow\n",
    "    \"\"\"\n",
    "    n_channels = max(x.shape[0] for x in images_np)\n",
    "    assert (n_channels == 3) or (n_channels == 1), \"images should have 1 or 3 channels\"\n",
    "\n",
    "    images_np = [x if (x.shape[0] == n_channels) else np.concatenate([x, x, x], axis=0) for x in images_np]\n",
    "\n",
    "    grid = get_image_grid(images_np, nrow)\n",
    "\n",
    "    plt.figure(figsize=(len(images_np) + factor, 12 + factor))\n",
    "\n",
    "    if images_np[0].shape[0] == 1:\n",
    "        plt.imshow(grid[0], cmap='gray', interpolation=interpolation)\n",
    "    else:\n",
    "        plt.imshow(grid.transpose(1, 2, 0), interpolation=interpolation)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return grid\n",
    "\n",
    "def load(path):\n",
    "    \"\"\"Load PIL image.\"\"\"\n",
    "    img = Image.open(path)\n",
    "    return img\n",
    "\n",
    "def get_image(path, imsize=-1):\n",
    "    \"\"\"Load an image and resize to a cpecific size.\n",
    "\n",
    "    Args:\n",
    "        path: path to image\n",
    "        imsize: tuple or scalar with dimensions; -1 for `no resize`\n",
    "    \"\"\"\n",
    "    img = load(path)\n",
    "\n",
    "    if isinstance(imsize, int):\n",
    "        imsize = (imsize, imsize)\n",
    "\n",
    "    if imsize[0]!= -1 and img.size != imsize:\n",
    "        if imsize[0] > img.size[0]:\n",
    "            img = img.resize(imsize, Image.BICUBIC)\n",
    "        else:\n",
    "            img = img.resize(imsize, Image.ANTIALIAS)\n",
    "\n",
    "    img_np = pil_to_np(img)\n",
    "\n",
    "    return img, img_np\n",
    "\n",
    "\n",
    "\n",
    "def fill_noise(x, noise_type):\n",
    "    \"\"\"Fills tensor `x` with noise of type `noise_type`.\"\"\"\n",
    "    if noise_type == 'u':\n",
    "        x.uniform_()\n",
    "    elif noise_type == 'n':\n",
    "        x.normal_()\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "def get_noise(input_depth, method, spatial_size, noise_type='u', var=1./10):\n",
    "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`)\n",
    "    initialized in a specific way.\n",
    "    Args:\n",
    "        input_depth: number of channels in the tensor\n",
    "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
    "        spatial_size: spatial size of the tensor to initialize\n",
    "        noise_type: 'u' for uniform; 'n' for normal\n",
    "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler.\n",
    "    \"\"\"\n",
    "    if isinstance(spatial_size, int):\n",
    "        spatial_size = (spatial_size, spatial_size)\n",
    "    if method == 'noise':\n",
    "        shape = [1, input_depth, spatial_size[0], spatial_size[1]]\n",
    "        net_input = torch.zeros(shape)\n",
    "\n",
    "        fill_noise(net_input, noise_type)\n",
    "        net_input *= var\n",
    "    elif method == 'meshgrid':\n",
    "        assert input_depth == 2\n",
    "        X, Y = np.meshgrid(np.arange(0, spatial_size[1])/float(spatial_size[1]-1), np.arange(0, spatial_size[0])/float(spatial_size[0]-1))\n",
    "        meshgrid = np.concatenate([X[None,:], Y[None,:]])\n",
    "        net_input=  np_to_torch(meshgrid)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    return net_input\n",
    "\n",
    "def pil_to_np(img_PIL):\n",
    "    '''Converts image in PIL format to np.array.\n",
    "\n",
    "    From W x H x C [0...255] to C x W x H [0..1]\n",
    "    '''\n",
    "    ar = np.array(img_PIL)\n",
    "\n",
    "    if len(ar.shape) == 3:\n",
    "        ar = ar.transpose(2,0,1)\n",
    "    else:\n",
    "        ar = ar[None, ...]\n",
    "\n",
    "    return ar.astype(np.float32) / 255.\n",
    "\n",
    "def np_to_pil(img_np):\n",
    "    '''Converts image in np.array format to PIL image.\n",
    "\n",
    "    From C x W x H [0..1] to  W x H x C [0...255]\n",
    "    '''\n",
    "    ar = np.clip(img_np*255,0,255).astype(np.uint8)\n",
    "\n",
    "    if img_np.shape[0] == 1:\n",
    "        ar = ar[0]\n",
    "    else:\n",
    "        ar = ar.transpose(1, 2, 0)\n",
    "\n",
    "    return Image.fromarray(ar)\n",
    "\n",
    "def np_to_torch(img_np):\n",
    "    '''Converts image in numpy.array to torch.Tensor.\n",
    "\n",
    "    From C x W x H [0..1] to  C x W x H [0..1]\n",
    "    '''\n",
    "    return torch.from_numpy(img_np)[None, :]\n",
    "\n",
    "def torch_to_np(img_var):\n",
    "    '''Converts an image in torch.Tensor format to np.array.\n",
    "\n",
    "    From 1 x C x W x H [0..1] to  C x W x H [0..1]\n",
    "    '''\n",
    "    return img_var.detach().cpu().numpy()[0]\n",
    "\n",
    "\n",
    "def optimize(optimizer_type, parameters, closure, LR, num_iter):\n",
    "    \"\"\"Runs optimization loop.\n",
    "\n",
    "    Args:\n",
    "        optimizer_type: 'LBFGS' of 'adam'\n",
    "        parameters: list of Tensors to optimize over\n",
    "        closure: function, that returns loss variable\n",
    "        LR: learning rate\n",
    "        num_iter: number of iterations\n",
    "    \"\"\"\n",
    "    if optimizer_type == 'LBFGS':\n",
    "        # Do several steps with adam first\n",
    "        optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "        for j in range(100):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Starting optimization with LBFGS')\n",
    "        def closure2():\n",
    "            optimizer.zero_grad()\n",
    "            return closure()\n",
    "        optimizer = torch.optim.LBFGS(parameters, max_iter=num_iter, lr=LR, tolerance_grad=-1, tolerance_change=-1)\n",
    "        optimizer.step(closure2)\n",
    "\n",
    "    elif optimizer_type == 'adam':\n",
    "        print('Starting optimization with ADAM')\n",
    "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "\n",
    "        for j in range(num_iter):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def get_noisy_image(img_np, sigma):\n",
    "    \"\"\"Adds Gaussian noise to an image.\n",
    "\n",
    "    Args:\n",
    "        img_np: image, np.array with values from 0 to 1\n",
    "        sigma: std of the noise\n",
    "    \"\"\"\n",
    "    img_noisy_np = np.clip(img_np + np.random.normal(scale=sigma, size=img_np.shape), 0, 1).astype(np.float32)\n",
    "    img_noisy_pil = np_to_pil(img_noisy_np)\n",
    "\n",
    "    return img_noisy_pil, img_noisy_np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Downsampler(nn.Module):\n",
    "    '''\n",
    "        http://www.realitypixels.com/turk/computergraphics/ResamplingFilters.pdf\n",
    "    '''\n",
    "    def __init__(self, n_planes, factor, kernel_type, phase=0, kernel_width=None, support=None, sigma=None, preserve_size=False):\n",
    "        super(Downsampler, self).__init__()\n",
    "\n",
    "        assert phase in [0, 0.5], 'phase should be 0 or 0.5'\n",
    "\n",
    "        if kernel_type == 'lanczos2':\n",
    "            support = 2\n",
    "            kernel_width = 4 * factor + 1\n",
    "            kernel_type_ = 'lanczos'\n",
    "\n",
    "        elif kernel_type == 'lanczos3':\n",
    "            support = 3\n",
    "            kernel_width = 6 * factor + 1\n",
    "            kernel_type_ = 'lanczos'\n",
    "\n",
    "        elif kernel_type == 'gauss12':\n",
    "            kernel_width = 7\n",
    "            sigma = 1/2\n",
    "            kernel_type_ = 'gauss'\n",
    "\n",
    "        elif kernel_type == 'gauss1sq2':\n",
    "            kernel_width = 9\n",
    "            sigma = 1./np.sqrt(2)\n",
    "            kernel_type_ = 'gauss'\n",
    "\n",
    "        elif kernel_type in ['lanczos', 'gauss', 'box']:\n",
    "            kernel_type_ = kernel_type\n",
    "\n",
    "        else:\n",
    "            assert False, 'wrong name kernel'\n",
    "\n",
    "\n",
    "        # note that `kernel width` will be different to actual size for phase = 1/2\n",
    "        self.kernel = get_kernel(factor, kernel_type_, phase, kernel_width, support=support, sigma=sigma)\n",
    "\n",
    "        downsampler = nn.Conv2d(n_planes, n_planes, kernel_size=self.kernel.shape, stride=factor, padding=0)\n",
    "        downsampler.weight.data[:] = 0\n",
    "        downsampler.bias.data[:] = 0\n",
    "\n",
    "        kernel_torch = torch.from_numpy(self.kernel)\n",
    "        for i in range(n_planes):\n",
    "            downsampler.weight.data[i, i] = kernel_torch\n",
    "\n",
    "        self.downsampler_ = downsampler\n",
    "\n",
    "        if preserve_size:\n",
    "\n",
    "            if  self.kernel.shape[0] % 2 == 1:\n",
    "                pad = int((self.kernel.shape[0] - 1) / 2.)\n",
    "            else:\n",
    "                pad = int((self.kernel.shape[0] - factor) / 2.)\n",
    "\n",
    "            self.padding = nn.ReplicationPad2d(pad)\n",
    "\n",
    "        self.preserve_size = preserve_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.preserve_size:\n",
    "            x = self.padding(input)\n",
    "        else:\n",
    "            x= input\n",
    "        self.x = x\n",
    "        return self.downsampler_(x)\n",
    "\n",
    "def get_kernel(factor, kernel_type, phase, kernel_width, support=None, sigma=None):\n",
    "    assert kernel_type in ['lanczos', 'gauss', 'box']\n",
    "\n",
    "    # factor  = float(factor)\n",
    "    if phase == 0.5 and kernel_type != 'box':\n",
    "        kernel = np.zeros([kernel_width - 1, kernel_width - 1])\n",
    "    else:\n",
    "        kernel = np.zeros([kernel_width, kernel_width])\n",
    "\n",
    "\n",
    "    if kernel_type == 'box':\n",
    "        assert phase == 0.5, 'Box filter is always half-phased'\n",
    "        kernel[:] = 1./(kernel_width * kernel_width)\n",
    "\n",
    "    elif kernel_type == 'gauss':\n",
    "        assert sigma, 'sigma is not specified'\n",
    "        assert phase != 0.5, 'phase 1/2 for gauss not implemented'\n",
    "\n",
    "        center = (kernel_width + 1.)/2.\n",
    "        print(center, kernel_width)\n",
    "        sigma_sq =  sigma * sigma\n",
    "\n",
    "        for i in range(1, kernel.shape[0] + 1):\n",
    "            for j in range(1, kernel.shape[1] + 1):\n",
    "                di = (i - center)/2.\n",
    "                dj = (j - center)/2.\n",
    "                kernel[i - 1][j - 1] = np.exp(-(di * di + dj * dj)/(2 * sigma_sq))\n",
    "                kernel[i - 1][j - 1] = kernel[i - 1][j - 1]/(2. * np.pi * sigma_sq)\n",
    "    elif kernel_type == 'lanczos':\n",
    "        assert support, 'support is not specified'\n",
    "        center = (kernel_width + 1) / 2.\n",
    "\n",
    "        for i in range(1, kernel.shape[0] + 1):\n",
    "            for j in range(1, kernel.shape[1] + 1):\n",
    "\n",
    "                if phase == 0.5:\n",
    "                    di = abs(i + 0.5 - center) / factor\n",
    "                    dj = abs(j + 0.5 - center) / factor\n",
    "                else:\n",
    "                    di = abs(i - center) / factor\n",
    "                    dj = abs(j - center) / factor\n",
    "\n",
    "\n",
    "                pi_sq = np.pi * np.pi\n",
    "\n",
    "                val = 1\n",
    "                if di != 0:\n",
    "                    val = val * support * np.sin(np.pi * di) * np.sin(np.pi * di / support)\n",
    "                    val = val / (np.pi * np.pi * di * di)\n",
    "\n",
    "                if dj != 0:\n",
    "                    val = val * support * np.sin(np.pi * dj) * np.sin(np.pi * dj / support)\n",
    "                    val = val / (np.pi * np.pi * dj * dj)\n",
    "\n",
    "                kernel[i - 1][j - 1] = val\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert False, 'wrong method name'\n",
    "\n",
    "    kernel /= kernel.sum()\n",
    "\n",
    "    return kernel\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def add_module(self, module):\n",
    "    self.add_module(str(len(self) + 1), module)\n",
    "\n",
    "torch.nn.Module.add = add_module\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dim, *args):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, input):\n",
    "        inputs = []\n",
    "        for module in self._modules.values():\n",
    "            inputs.append(module(input))\n",
    "\n",
    "        inputs_shapes2 = [x.shape[2] for x in inputs]\n",
    "        inputs_shapes3 = [x.shape[3] for x in inputs]\n",
    "\n",
    "        if np.all(np.array(inputs_shapes2) == min(inputs_shapes2)) and np.all(np.array(inputs_shapes3) == min(inputs_shapes3)):\n",
    "            inputs_ = inputs\n",
    "        else:\n",
    "            target_shape2 = min(inputs_shapes2)\n",
    "            target_shape3 = min(inputs_shapes3)\n",
    "\n",
    "            inputs_ = []\n",
    "            for inp in inputs:\n",
    "                diff2 = (inp.size(2) - target_shape2) // 2\n",
    "                diff3 = (inp.size(3) - target_shape3) // 2\n",
    "                inputs_.append(inp[:, :, diff2: diff2 + target_shape2, diff3:diff3 + target_shape3])\n",
    "\n",
    "        return torch.cat(inputs_, dim=self.dim)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class GenNoise(nn.Module):\n",
    "    def __init__(self, dim2):\n",
    "        super(GenNoise, self).__init__()\n",
    "        self.dim2 = dim2\n",
    "\n",
    "    def forward(self, input):\n",
    "        a = list(input.size())\n",
    "        a[1] = self.dim2\n",
    "        # print (input.data.type())\n",
    "\n",
    "        b = torch.zeros(a).type_as(input.data)\n",
    "        b.normal_()\n",
    "\n",
    "        x = torch.autograd.Variable(b)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "        https://arxiv.org/abs/1710.05941\n",
    "        The hype was so huge that I could not help but try it\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "        self.s = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.s(x)\n",
    "\n",
    "\n",
    "def act(act_fun = 'LeakyReLU'):\n",
    "    '''\n",
    "        Either string defining an activation function or module (e.g. nn.ReLU)\n",
    "    '''\n",
    "    if isinstance(act_fun, str):\n",
    "        if act_fun == 'LeakyReLU':\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act_fun == 'Swish':\n",
    "            return Swish()\n",
    "        elif act_fun == 'ELU':\n",
    "            return nn.ELU()\n",
    "        elif act_fun == 'none':\n",
    "            return nn.Sequential()\n",
    "        else:\n",
    "            assert False\n",
    "    else:\n",
    "        return act_fun()\n",
    "\n",
    "\n",
    "def bn(num_features):\n",
    "    return nn.BatchNorm2d(num_features)\n",
    "\n",
    "\n",
    "def conv(in_f, out_f, kernel_size, stride=1, bias=True, pad='zero', downsample_mode='stride'):\n",
    "    downsampler = None\n",
    "    if stride != 1 and downsample_mode != 'stride':\n",
    "\n",
    "        if downsample_mode == 'avg':\n",
    "            downsampler = nn.AvgPool2d(stride, stride)\n",
    "        elif downsample_mode == 'max':\n",
    "            downsampler = nn.MaxPool2d(stride, stride)\n",
    "        elif downsample_mode  in ['lanczos2', 'lanczos3']:\n",
    "            downsampler = Downsampler(n_planes=out_f, factor=stride, kernel_type=downsample_mode, phase=0.5, preserve_size=True)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        stride = 1\n",
    "\n",
    "    padder = None\n",
    "    to_pad = int((kernel_size - 1) / 2)\n",
    "    if pad == 'reflection':\n",
    "        padder = nn.ReflectionPad2d(to_pad)\n",
    "        to_pad = 0\n",
    "\n",
    "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
    "\n",
    "\n",
    "    layers = filter(lambda x: x is not None, [padder, convolver, downsampler])\n",
    "    return nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy.random import normal\n",
    "from numpy.linalg import svd\n",
    "from math import sqrt\n",
    "import torch.nn.init\n",
    "\n",
    "class ResidualSequential(nn.Sequential):\n",
    "    def __init__(self, *args):\n",
    "        super(ResidualSequential, self).__init__(*args)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = super(ResidualSequential, self).forward(x)\n",
    "        # print(x.size(), out.size())\n",
    "        x_ = None\n",
    "        if out.size(2) != x.size(2) or out.size(3) != x.size(3):\n",
    "            diff2 = x.size(2) - out.size(2)\n",
    "            diff3 = x.size(3) - out.size(3)\n",
    "            # print(1)\n",
    "            x_ = x[:, :, diff2 /2:out.size(2) + diff2 / 2, diff3 / 2:out.size(3) + diff3 / 2]\n",
    "        else:\n",
    "            x_ = x\n",
    "        return out + x_\n",
    "\n",
    "    def eval(self):\n",
    "        print(2)\n",
    "        for m in self.modules():\n",
    "            m.eval()\n",
    "        exit()\n",
    "\n",
    "\n",
    "def get_block(num_channels, norm_layer, act_fun):\n",
    "    layers = [\n",
    "        nn.Conv2d(num_channels, num_channels, 3, 1, 1, bias=False),\n",
    "        norm_layer(num_channels, affine=True),\n",
    "        act(act_fun),\n",
    "        nn.Conv2d(num_channels, num_channels, 3, 1, 1, bias=False),\n",
    "        norm_layer(num_channels, affine=True),\n",
    "    ]\n",
    "    return layers\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_input_channels, num_output_channels, num_blocks, num_channels, need_residual=True, act_fun='LeakyReLU', need_sigmoid=True, norm_layer=nn.BatchNorm2d, pad='reflection'):\n",
    "        '''\n",
    "            pad = 'start|zero|replication'\n",
    "        '''\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        if need_residual:\n",
    "            s = ResidualSequential\n",
    "        else:\n",
    "            s = nn.Sequential\n",
    "\n",
    "        stride = 1\n",
    "        # First layers\n",
    "        layers = [\n",
    "            # nn.ReplicationPad2d(num_blocks * 2 * stride + 3),\n",
    "            conv(num_input_channels, num_channels, 3, stride=1, bias=True, pad=pad),\n",
    "            act(act_fun)\n",
    "        ]\n",
    "        # Residual blocks\n",
    "        # layers_residual = []\n",
    "        for i in range(num_blocks):\n",
    "            layers += [s(*get_block(num_channels, norm_layer, act_fun))]\n",
    "\n",
    "        layers += [\n",
    "            nn.Conv2d(num_channels, num_channels, 3, 1, 1),\n",
    "            norm_layer(num_channels, affine=True)\n",
    "        ]\n",
    "\n",
    "        # if need_residual:\n",
    "        #     layers += [ResidualSequential(*layers_residual)]\n",
    "        # else:\n",
    "        #     layers += [Sequential(*layers_residual)]\n",
    "\n",
    "        # if factor >= 2:\n",
    "        #     # Do upsampling if needed\n",
    "        #     layers += [\n",
    "        #         nn.Conv2d(num_channels, num_channels *\n",
    "        #                   factor ** 2, 3, 1),\n",
    "        #         nn.PixelShuffle(factor),\n",
    "        #         act(act_fun)\n",
    "        #     ]\n",
    "        layers += [\n",
    "            conv(num_channels, num_output_channels, 3, 1, bias=True, pad=pad),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def dcgan(inp=2,\n",
    "          ndf=32,\n",
    "          num_ups=4, need_sigmoid=True, need_bias=True, pad='zero', upsample_mode='nearest', need_convT = True):\n",
    "\n",
    "    layers= [nn.ConvTranspose2d(inp, ndf, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "             nn.BatchNorm2d(ndf),\n",
    "             nn.LeakyReLU(True)]\n",
    "\n",
    "    for i in range(num_ups-3):\n",
    "        if need_convT:\n",
    "            layers += [ nn.ConvTranspose2d(ndf, ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(ndf),\n",
    "                        nn.LeakyReLU(True)]\n",
    "        else:\n",
    "            layers += [ nn.Upsample(scale_factor=2, mode=upsample_mode),\n",
    "                        nn.Conv2d(ndf, ndf, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(ndf),\n",
    "                        nn.LeakyReLU(True)]\n",
    "\n",
    "    if need_convT:\n",
    "        layers += [nn.ConvTranspose2d(ndf, 3, 4, 2, 1, bias=False),]\n",
    "    else:\n",
    "        layers += [nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                   nn.Conv2d(ndf, 3, kernel_size=3, stride=1, padding=1, bias=False)]\n",
    "\n",
    "\n",
    "    if need_sigmoid:\n",
    "        layers += [nn.Sigmoid()]\n",
    "\n",
    "    model =nn.Sequential(*layers)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "# from skimage.measure import compare_psnr\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "import cv2\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "imsize =-1\n",
    "PLOT = True\n",
    "sigma = 25\n",
    "sigma_ = sigma/255.\n",
    "names = ['yaleB01_P00A-020E+10.png', 'yaleB02_P00A-010E+00.png', 'yaleB05_P00A-020E-10.png', \\\n",
    "         'yaleB06_P00A+020E+10.png', 'yaleB07_P00A+000E+00.png']\n",
    "\n",
    "# deJPEG\n",
    "# fname = 'data/denoising/0.jpg'\n",
    "\n",
    "i = 4\n",
    "## denoising\n",
    "fname = 'data/denoising/'+names[i]\n",
    "filename = 'data/denoised/sigma^2='+str(sigma)+'/B0'+str(i+1)+'_scale'+str(sigma)+'.png'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# de-JPEG\n",
    "if fname == 'data/denoising/0.jpg':\n",
    "    img_noisy_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "    img_noisy_np = pil_to_np(img_noisy_pil)\n",
    "\n",
    "    # As we don't have ground truth\n",
    "    img_pil = img_noisy_pil\n",
    "    img_np = img_noisy_np\n",
    "\n",
    "    if PLOT:\n",
    "        plot_image_grid([img_np], 4, 5);\n",
    "\n",
    "else: #denoising\n",
    "    # Add synthetic noise\n",
    "    img_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "    img_np = pil_to_np(img_pil)\n",
    "\n",
    "    if img_np.shape[0] == 1:\n",
    "        img_np = np.stack((img_np[0],)*3, axis=0)\n",
    "\n",
    "    img_noisy_pil, img_noisy_np = get_noisy_image(img_np, sigma_)\n",
    "\n",
    "    if PLOT:\n",
    "        plot_image_grid([img_np, img_noisy_np], 4, 6);\n",
    "# else:\n",
    "#     assert False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "INPUT = 'noise' # 'meshgrid'\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # 'net,input'\n",
    "\n",
    "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
    "LR = 0.01\n",
    "\n",
    "OPTIMIZER='adam' # 'LBFGS'\n",
    "show_every = 100\n",
    "exp_weight=0.99\n",
    "\n",
    "if fname == 'data/denoising/0.jpg':\n",
    "    num_iter = 2400\n",
    "    input_depth = 3\n",
    "    figsize = 5\n",
    "\n",
    "    net = skip(\n",
    "                input_depth, 3,\n",
    "                num_channels_down = [8, 16, 32, 64, 128],\n",
    "                num_channels_up   = [8, 16, 32, 64, 128],\n",
    "                num_channels_skip = [0, 0, 0, 4, 4],\n",
    "                upsample_mode='bilinear',\n",
    "                need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU')\n",
    "\n",
    "    net = net.type(dtype)\n",
    "\n",
    "else:\n",
    "    num_iter = 1000\n",
    "    input_depth = 32\n",
    "    figsize = 4\n",
    "\n",
    "\n",
    "    net = get_net(input_depth, 'skip', pad,\n",
    "                  skip_n33d=128,\n",
    "                  skip_n33u=128,\n",
    "                  skip_n11=4,\n",
    "                  num_scales=5,\n",
    "                  upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0])).type(dtype).detach()\n",
    "\n",
    "# Compute number of parameters\n",
    "s  = sum([np.prod(list(p.size())) for p in net.parameters()]);\n",
    "print ('Number of params: %d' % s)\n",
    "\n",
    "# Loss\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "out_avg = None\n",
    "last_net = None\n",
    "psrn_noisy_last = 0\n",
    "psrn_gt_last = 0\n",
    "\n",
    "i = 0\n",
    "def closure():\n",
    "\n",
    "    global i, out_avg, psrn_noisy_last, last_net, net_input, psrn_gt_last\n",
    "\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "\n",
    "    out = net(net_input)\n",
    "\n",
    "    # Smoothing\n",
    "    if out_avg is None:\n",
    "        out_avg = out.detach()\n",
    "    else:\n",
    "        out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "\n",
    "    total_loss = mse(out, img_noisy_torch)\n",
    "    total_loss.backward()\n",
    "\n",
    "    psrn_noisy = peak_signal_noise_ratio(img_noisy_np, out.detach().cpu().numpy()[0])\n",
    "    psrn_gt    = peak_signal_noise_ratio(img_np, out.detach().cpu().numpy()[0])\n",
    "    psrn_gt_sm = peak_signal_noise_ratio(img_np, out_avg.detach().cpu().numpy()[0])\n",
    "    # ssim_score = structural_similarity(img_noisy_np.transpose(1,2,0), out.detach().cpu().numpy()[0].transpose(1,2,0),multichannel=True)\n",
    "\n",
    "    # Note that we do not have GT for the \"snail\" example\n",
    "    # So 'PSRN_gt', 'PSNR_gt_sm' make no sense\n",
    "    if  PLOT and i % show_every == 0:\n",
    "        print(f'Iteration {i} Loss {total_loss.item()} PSNR_noisy {psrn_noisy} PSRN_gt: {psrn_gt}')\n",
    "        out_np = torch_to_np(out)\n",
    "        plot_image_grid([np.clip(out_np, 0, 1),\n",
    "                         np.clip(torch_to_np(out_avg), 0, 1)], factor=figsize, nrow=1)\n",
    "\n",
    "\n",
    "\n",
    "    # Backtracking\n",
    "    if i % show_every:\n",
    "        if psrn_noisy - psrn_noisy_last < -5:\n",
    "            print('Falling back to previous checkpoint.')\n",
    "\n",
    "            for new_param, net_param in zip(last_net, net.parameters()):\n",
    "                net_param.data.copy_(new_param.cuda())\n",
    "\n",
    "            return total_loss*0\n",
    "        else:\n",
    "            last_net = [x.detach().cpu() for x in net.parameters()]\n",
    "            psrn_noisy_last = psrn_noisy\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_np = torch_to_np(net(net_input))\n",
    "\n",
    "psnr = peak_signal_noise_ratio(img_np, out_np)\n",
    "ssim = structural_similarity(img_np.transpose(1,2,0), out_np.transpose(1,2,0), multichannel=True)\n",
    "\n",
    "fig = plt.figure(figsize=(35, 20))\n",
    "fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(img_np.transpose(1,2,0))\n",
    "plt.title(\"Original\",fontsize=30)\n",
    "\n",
    "fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(img_noisy_np.transpose(1,2,0))\n",
    "plt.title(\"Noised with Gaussian \\u03C3^2=\"+str(sigma),fontsize=30)\n",
    "\n",
    "fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(out_np.transpose(1,2,0))\n",
    "plt.title(f\"After Denoising by Deep Image Prior\\n PSNR {psnr:.2f} dB\",fontsize=30)\n",
    "\n",
    "plt.savefig(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And here is the result of the Deep Image Prior.\n",
    "\n",
    "[<img src=\"./deepprior.png\" width=\"400\"/>](image.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is the result of all of our methods under different scale of noise\n",
    "\n",
    "[<img src=\"./result.png\" width=\"600\"/>](image.png)\n",
    "\n",
    "The U-net model achieves the highest PSNR value. For the deep image prior model, though it's not good as the U-net model, it gives a good result without using a lot of data (actually it only uses one image). And the total variation minimization, it can not beat the UNet based on PSNR score, but it can also be a good choice because of the cheap computation. As for low rank representation, even it has very low PSNR score, the visual effect is not bad and it is promising in other perspectives."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}